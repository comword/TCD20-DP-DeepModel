{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "src_dir = os.path.join(\"../src\")\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "from model.vtn import VTNBuilder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "model = VTNBuilder()\n",
    "test = tf.random.uniform((1, 3, 15, 224, 224))   # B, C, F, H, W\n",
    "frame_idx = np.arange(0, 1*15).reshape((1, 15))\n",
    "out = model([test, frame_idx])\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-16 21:01:37.598415: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.broadcast_to), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(1, 1, 384) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x1054fdbe0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x1054fdbe0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFRobertaPooler.call of <transformers.models.roberta.modeling_tf_roberta.TFRobertaPooler object at 0x17a6ab040>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpznv794l9.py, line 10)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFRobertaPooler.call of <transformers.models.roberta.modeling_tf_roberta.TFRobertaPooler object at 0x17a6ab040>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpznv794l9.py, line 10)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "(1, 16)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class WarmupSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(WarmupSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "learning_rate = WarmupSchedule(128)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open(\"../configs/vtn.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "arch = type(model).__name__\n",
    "ckpt = tf.train.Checkpoint(arch=tf.Variable(arch),\n",
    "                            epoch=tf.Variable(1),\n",
    "                            model=model,\n",
    "                            optimizer=optimizer,\n",
    "                            monitor_best=tf.Variable(0.0),\n",
    "                            config=tf.Variable(json.dumps(config)))\n",
    "ckpt.write(\"../saved/test\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../saved/test'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "arch = tf.Variable(\"\")\n",
    "epoch = tf.Variable(1)\n",
    "monitor_best = tf.Variable(0.0)\n",
    "config = tf.Variable(\"\")\n",
    "ckpt = tf.train.Checkpoint(arch=arch,\n",
    "                            epoch=epoch,\n",
    "                            model=model,\n",
    "                            optimizer=optimizer,\n",
    "                            monitor_best=monitor_best,\n",
    "                            config=config)\n",
    "ckpt.restore(\"../saved/test\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x17a2c0850>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "int(epoch)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "float(monitor_best)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "json.loads(config.numpy().decode(\"utf-8\"))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'DP_Posture',\n",
       " 'n_gpu': 1,\n",
       " 'save_dir': 'saved/',\n",
       " 'arch': {'type': 'VTNBuilder',\n",
       "  'args': {'backbone': 'EfficientNetB0', 'n_classes': 16}},\n",
       " 'data_loader': {'type': 'FrameDataLoaderTF',\n",
       "  'args': {'data_path': 'data/anonymisedVideos',\n",
       "   'batch_size': 3,\n",
       "   'shuffle': True,\n",
       "   'validation_split': 0.1,\n",
       "   'resolution': [224, 224],\n",
       "   'batch_frame': 15,\n",
       "   'batch_second': 5,\n",
       "   'num_clips': 12,\n",
       "   'resize_fac': [0.8, 1.2],\n",
       "   'mean_norm': [0.45, 0.45, 0.45],\n",
       "   'std_norm': [0.225, 0.225, 0.225]}},\n",
       " 'trainer': {'epochs': 40,\n",
       "  'save_period': 10,\n",
       "  'verbosity': 2,\n",
       "  'monitor': 'max val_accuracy',\n",
       "  'early_stop': 5,\n",
       "  'lr_dmodel': 128,\n",
       "  'tensorboard': True}}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}